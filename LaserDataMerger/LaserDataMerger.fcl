## 
##  A "minimal" Reconstruction for uboone data
##
#include "services_microboone.fcl"
#include "reco_uboone_data_minimal.fcl"
#include "merger.fcl"

process_name: LaserDataMerger

services:
{
  scheduler:               { defaultExceptions: false }    # Make all uncaught exceptions fatal.
  # Load the service that manages root files for histograms.
  TFileService:            { fileName: "TimeInfo-%r.root" }
  #Timing:                  {}
  #SimpleMemoryCheck:       { ignoreTotal: 1 } # default is one
  #RandomNumberGenerator:   {} #ART native random number generator
  #message:                 @local::microboone_message_services_prod_debug
  #FileCatalogMetadata:     @local::art_file_catalog_data
  @table::microboone_reco_minimal_services
}
services.DetectorClocksService.InheritClockConfig: false
services.DatabaseUtil.ShouldConnect: false
#services.DetPedestalService.DetPedestalRetrievalAlg.UseDB: true

#source is now a root file
source:
{
  module_type: RootInput
  #maxEvents:  1        # Number of events to create
}

# Define and configure some modules to do work on each event.
# First modules are defined; they are scheduled later.
# Modules are grouped by type.
physics:
{
 #filters:
 #{ 
 # @table::microboone_reco_minimal_filters
 #}

 producers:
  {
        LaserDataMerger:    @local::LaserDataMerger
  }

 #define the producer and filter modules for this path, order matters, 
 #filters reject all following items.  see lines starting physics.producers below
 reco: [ LaserDataMerger ]

 #define the output stream, there could be more than one if using filters 
 stream1:  [ out1 ]

 #trigger_paths is a keyword and contains the paths that modify the art::event, 
 #ie filters and producers
 trigger_paths: [reco]

 #analysis : [LaserDataMerger] 

 #end_paths is a keyword and contains the paths that do not modify the art::Event, 
 #ie analyzers and output streams.  these all run simultaneously
 #end_paths:     [analysis]  
}

#block to define where the output goes.  if you defined a filter in the physics
#block and put it in the trigger_paths then you need to put a SelectEvents: {SelectEvents: [XXX]}
#entry in the output stream you want those to go to, where XXX is the label of the filter module(s)
outputs:
{
 out1:
 {
   module_type: RootOutput
   fileName:    "LaserDataMerged-%r-%05s.root"
   #sam_ignore:  true
   dataTier:    "reconstructed-2d"
   compressionLevel: 1
   outputCommands: ["keep *_*_*_*",  "drop raw::RawDigits_*_*_*", "drop raw::OpDetWaveforms_*_*_*", "drop raw::BeamInfo_*_*_*"]
   compressionLevel: 1
 }
}

### Here we include the file giving us run/data dependent overrides
##include "uboone_data_runSettings.fcl"

### Here we try to suppress known and pointless messages
services.message.destinations :
{
  STDCOUT: 
  {
     type:      "cout"      #tells the message service to output this destination to cout
     threshold: "WARNING"   #tells the message service that this destination applies to WARNING and higher level messages
     append:     true       #says to append all messages to the output
     categories:
     {
       ChannelFilter:
       {
         limit: 0
         reportEvery: 0
       }
       TrackStitcher:
       {
         limit: 0
         reportEvery: 0
       }
       CRHitRemoval:
       {
         limit: 0
         reportEvery: 0
       }
       default:
       {
         limit: -1  #don't print anything at the infomsg level except the explicitly named categories
         reportEvery: 1
       }
     }
  }
}
